\title{\pkg{SWMPr}: An R Package for Retrieving, Organizing, and Analyzing Environmental Data for Estuaries}
\author{by Marcus W Beck}

\maketitle

\abstract{
The System-Wide Monitoring Program (SWMP) was implemented in 1995 by the US National Estuarine Research Reserve System. This program has provided two decades of continuous monitoring data at over 140 fixed stations in 28 estuaries. However, the increasing quantity of data provided by the monitoring network has complicated broad-scale comparisons between systems and, in some cases, prevented simple trend analysis of water quality parameters at individual sites.  This article describes the \CRANpkg{SWMPr} package that provides several functions to facilitate data retrieval, organization, and analysis of time series data in the reserve estuaries.  Previously unavailable functions for estuaries are also provided to estimate rates of ecosystem metabolism using the open-water method.  The \CRANpkg{SWMPr} package has facilitated a cross-reserve comparison of water quality trends and links quantitative information with analysis tools that has use for more generic applications to environmental time series.
}

\section{Introduction}

The development of low-cost, automated sensors that collect data in near real-time has enabled a proliferation of standardized environmental monitoring programs \citep{Glasgow04,Fries08}.  An invaluable source of monitoring data for coastal regions in the United States is provided by the National Estuarine Research Reserve System (NERRS, \url{http://www.nerrs.noaa.gov/}).  This network of 28 estuary reserves was created to address long-term research, monitoring, education, and stewardship goals in support of coastal management.  The System-Wide Monitoring Program (SWMP) was implemented in 1995 at over 140 stations across the reserves to provide a robust, long-term monitoring system for water quality, weather, and land-use/habitat change.  Environmental researchers have expressed a need for quantitative analysis tools to evaluate trends in water quality time series given the quantity and quality of data provided by SWMP \citep{SWMP14}.

This article describes the \CRANpkg{SWMPr} package that was developed for estuary monitoring data from the System-Wide Monitoring Program.  Functions provided by \CRANpkg{SWMPr} address many common issues working with large datasets created from automated sensor networks, such as data pre-processing to remove unwanted information, combining data from different sources, and exploratory analyses to identify parameters of interest.  Additionally, web applications derived from \CRANpkg{SWMPr} and \CRANpkg{shiny} illustrate potential applications using the functions in this package.  The software is provided specifically for use with NERRS data, although many of the applications are relevant for addressing common challenges working with large environmental datasets.

\section{Overview of the SWMP network}

The \pkg{SWMPr} package was developed for the continuous abiotic monitoring network that represents a majority of SWMP data and, consequently, the most challenging to evaluate.  Abiotic elements monitored at each reserve include water quality (water temperature, specific conductivity, salinity, dissolved oxygen concentration, dissolved oxygen saturation, depth, pH, turbidity, chlorophyll fluorescence), weather (air temperature, relative humidity, barometric pressure, wind speed, wind direction, photosynthetically active radiation, precipitation), and nutrient data (orthophosphate, ammonium, nitrite, nitrate, nitrite + nitrate, chlorophyll a).  Each of the 28 estuary reserves has no less than four water quality stations and one weather station at fixed locations.  Water quality and weather data are collected at 15 minute intervals, whereas nutrient data are collected monthly at each water quality station.  Data are made available through the Centralized Data Management Office (CDMO) web portal (\url{http://cdmo.baruch.sc.edu/}), where quality assurance/quality control (QAQC) measures are used to screen the information for accuracy and reliability.  The final data include timestamped observations with relevant QAQC flags.

At the time of writing, the CDMO web portal provides over 60 million water quality, weather, and nutrient records that have been authenticated through systematic QAQC procedures.  Records for each station are identified by a 7 or 8 character name that specifies the reserve, station, and parameter type.  For example, `apaebwq' is the water quality identifier (`wq') for the East Bay station (`eb') at the Apalachicola reserve (`apa').  Similarly, a suffix of `met' or `nut' specifies the weather (meteorological) or nutrient stations.  All reserve names, stations, and date ranges for each parameter type can be viewed on the CDMO website. Alternatively, the \code{site\_codes} (all sites) or \code{site\_codes\_ind} (single site) functions provided by \pkg{SWMPr} can be used.  As noted below, an IP address must be registered with CDMO before using the data retrieval functions in \pkg{SWMPr}.  Web services are provided by CDMO for direct access to SWMP data through http requests, in addition to standard graphical user interface options for selecting data.  The data retrieval functions in \pkg{SWMPr} are simple calls to the existing retrieval functions on CDMO web services, as explained below.

\section{Structure of the \pkg{SWMPr} package}



\pkg{SWMPr} functions are categorized by one of three steps in the data workflow: \Bigtxt{retrieving}, \Bigtxt{organizing}, and \Bigtxt{analyzing}.  Functions for retrieving are used to import the data into R as a \code{"swmpr"} object class.  Functions for organizing and analyzing the data provide methods for working with a \code{"swmpr"} object.  The following describes the package structure, beginning with the retrieval functions, a description of the \code{"swmpr"} object returned after retrieval, and, finally, the organizing and analyzing functions.

\subsection{Data retrieval}

\pkg{SWMPr} can import data into R through direct download from the CDMO or by importing local data that was previously downloaded (Table~\ref{tab:retrieve}). The IP address for the computer making the request must be registered if the first approach is used (see CDMO \href{http://cdmo.baruch.sc.edu/data/qaqc.cfm}{website}).  The \code{site\_codes} or \code{site\_codes\_ind} functions can be used to view site metadata. 

% table for retrieval functions
%latex.default(to_tab[, "Description", drop = F], file = "", caption = "Retrieval functions available from the \\pkg{SWMPr} package. Full documentation for each function is in the help file (e.g., execute \\code{?all\\_params} for individual functions or \\code{help.search(`retrieve', package = `SWMPr')} for all).",     rowlabel = "Function", colheads = "Description", rowname = to_tab$Functions,     caption.loc = "top", col.just = c("p{3.5in}"), label = "tab:retrieve",     table.env = FALSE, where = "!tbp")%
\begin{table}[!tbp]
\caption{Retrieval functions available from the \pkg{SWMPr} package. Full documentation for each function is in the help file (e.g., execute \code{?all\_params} for individual functions or \code{help.search(`retrieve', package = `SWMPr')} for all).\label{tab:retrieve}} 
\begin{center}
\begin{tabular}{lp{3.5in}}
\hline\hline
\multicolumn{1}{l}{Function}&\multicolumn{1}{c}{Description}\tabularnewline
\hline
\code{all\_params}&Retrieve records starting with the most recent at a given station, all parameters.  Wrapper to \code{exportAllParamsXMLNew} function on web services.\tabularnewline
\code{all\_params\_dtrng}&Retrieve records of all parameters within a given date range for a station.  Optional argument for a single parameter. Wrapper to \code{exportAllParamsDateRangeXMLNew}.\tabularnewline
\code{import\_local}&Import files from a local path.  The files must be in a specific format, such as those returned from the CDMO using the zip downloads option.\tabularnewline
\code{single\_param}&Retrieve records for a single parameter starting with the most recent at a given station.  Wrapper to \code{exportSingleParamXMLNew} function on web services.\tabularnewline
\code{site\_codes}&Get metadata for all stations, wrapper to \code{exportStationCodesXMLNew} function on web services.\tabularnewline
\code{site\_codes\_ind}&Get metadata for all stations at a single site, wrapper to \code{NERRFilterStationCodesXMLNew} function on web services.\tabularnewline
\hline
\end{tabular}\end{center}

\end{table}


\begin{example}
# retrieve metadata for all sites
site_codes()

# retrieve metadata for a single site
site_codes_ind('apa')
\end{example}

Retrieval functions to import data directly into R from the CDMO include \code{all\_params}, \code{all\_params\_dtrng}, and \code{single\_param}. Due to rate limitations on the CDMO server, the retrieval functions return a limited number of records with each request.  However, the \pkg{SWMPr} functions use the native CDMO web services iteratively (i.e., within a loop) to obtain all requested records.  Download time can be excessive for longer time series.     
\begin{example}
# all parameters for a station, most recent
all_params('hudscwq')

# get all parameters within a date range
all_params_dtrng('hudscwq', dtrng = c('09/01/2013', '10/01/2013'))

# get single parameter within a date range
all_params_dtrng('hudscwq', dtrng = c('09/01/2013', '10/01/2013'), 
  param = 'do_mgl')

# single parameter for a station, most recent
single_param('hudscwq', param = 'do_mgl')
\end{example}

The second approach for data retrieval is to use the \code{import\_local} function to import data into R after downloading from CDMO.  This approach is most appropriate for large data requests. The \code{import\_local} function is designed for data from the \href{http://cdmo.baruch.sc.edu/aqs/zips.cfm}{zip downloads} feature in the advanced query section of the CDMO website. The zip downloads feature can be used to obtain a large number of records from multiple stations in one request.  The downloaded data will be in a compressed folder that includes multiple .csv files by year for a given data type (e.g., apacpwq2002.csv, apacpwq2003.csv, apacpnut2002.csv, etc.).  The \code{import\_local} function can be used to import files directly from the zipped folder.

\subsection{The \code{"swmpr"} object class}

All data retrieval functions return a \code{"swmpr"} object that includes relevant data and several attributes describing the dataset.  The data include a \code{datetimestamp} column in the timezone for a station and additional parameters for the data type (weather, nutrients, or water quality).  Corresponding QAQC columns for each parameter are also returned if provided by the initial data request.  The following shows an example of the raw data imported using \code{all\_params}.

\begin{example}
# import all paramaters for the station
# three most recent records
exdat <- all_params('apadbwq', Max = 3, trace = F)
exdat
##         datetimestamp temp f_temp spcond f_spcond sal f_sal do_pct
## 1 2015-11-03 11:15:00   26      0     45        0  29     0     78
## 2 2015-11-03 11:30:00   26      0     46        0  30     0     76
## 3 2015-11-03 11:45:00   26      0     46        0  30     0     75
##   f_do_pct do_mgl f_do_mgl depth f_depth ph f_ph turb f_turb chlfluor
## 1        0      5        0     2       0  8    0    2      0       NA
## 2        0      5        0     2       0  8    0    5      0       NA
## 3        0      5        0     2       0  8    0    5      0       NA
##   f_chlfluor level f_level cdepth clevel f_cdepth f_clevel
## 1         -2    NA      -1      2     NA        3         
## 2         -2    NA      -1      2     NA        3         
## 3         -2    NA      -1      2     NA        3
\end{example}

The attributes of a \code{"swmpr"} object are descriptors that are appended to the raw data (Table~\ref{tab:attributes}).  These act as metadata that are used internally by many of the package functions and are updated as the data are processed. The attributes are not visible with the raw data but can be viewed as follows.

\begin{example}
# import sample data from package
data(apadbwq)
dat <- apadbwq

# view all attributes of dat
attributes(dat)
 
# view a single attribute of dat
attr(dat, 'station')
\end{example}
 
% attributes table
%latex.default(to_tab[, -1, drop = F], file = "", caption = "Attributes of a \\code{\"swmpr\"} object that describe characteristics of the data.",     rowlabel = "Attributes", colheads = c("Class", "Description"),     rowname = to_tab$Attributes, caption.loc = "top", insert.bottom = foot,     col.just = c("p{0.75in}", "p{3.25in}"), label = "tab:attributes",     table.env = FALSE, where = "!tbp")%
\begin{table}[!tbp]
\caption{Attributes of a \code{"swmpr"} object that describe characteristics of the data.\label{tab:attributes}} 
\begin{center}
\begin{tabular}{lp{0.75in}p{3.25in}}
\hline\hline
\multicolumn{1}{l}{Attributes}&\multicolumn{1}{c}{Class}&\multicolumn{1}{c}{Description}\tabularnewline
\hline
\code{names}&character&Column names of the entire data set, inherited from the \code{data.frame} object class.\tabularnewline
\code{row.names}&integer&Row names of the data set, inherited from the \code{data.frame} object class.\tabularnewline
\code{class}&character&Class of the data object indicating \code{"swmpr"} and \code{"data.frame"}.\tabularnewline
\code{station}&character&Station identifier used by NERRS as a string with 7 or 8 characters.\tabularnewline
\code{parameters}&character&Character vector of column names for data parameters, e.g., \code{'do\_mgl'}, \code{'turb'}, etc.\tabularnewline
\code{qaqc\_cols}&logical&Indicates if QAQC columns are present in the raw data.\tabularnewline
\code{date\_rng}&POSIXct&Start and end dates for the data.\tabularnewline
\code{timezone}&character&Timezone of the station using the city/country format\textsuperscript{a}.\tabularnewline
\code{stamp\_class}&character&Class of the \code{datetimestamp} column, usually \code{"POSIXct"} unless data have been aggregated.\tabularnewline
\hline
\end{tabular}\end{center}

\textsuperscript{a}\footnotesize Time zones that do not observe daylight savings are used for \code{"swmpr"} objects and may not be cities in the United States.  For example, \code{America/Jamaica} is used for Eastern Standard Time.\end{table}


The \code{"swmpr"} object class was created for use with the organizing and analyzing functions.  This uses the standard S3 object class system for R, such that specific methods for generic functions are developed for the object class.  A \code{"swmpr"} object also secondarily inherits methods from the \code{"data.frame"} class. Available methods for the \code{"swmpr"} class are described below and can also be viewed:
 
\begin{example}
# view available methods for swmpr class
methods(class = 'swmpr')
\end{example}

\subsection{Data organizing}

The organize functions are used to `clean' or prepare the imported data for analysis, including viewing and removal of QAQC flags, subsetting, combining replicate nutrient observations, creating a standardized time series, and combining data of different types (Table~\ref{tab:organize}).

The \code{qaqc} function is a simple screen to retain observations from the data with specified QAQC flags (see \url{http://cdmo.baruch.sc.edu/data/qaqc.cfm}). Each parameter in the imported \code{"swmpr"} object will have a corresponding QAQC column of the same name with the added prefix \code{f\_} (e.g., \code{f\_do\_mgl} for \code{do\_mgl}).  Values in the QAQC column range from -5 to 5 to indicate the QAQC flag that was assigned by CDMO during initial processing.  The \code{qaqc} function is used to remove observations in the raw data with given flags, with the default option to retain only values with the \code{0} QAQC flag (i.e., passed initial CDMO checks).     Additionally, simple filters are used to remove obviously bad values, e.g., wind speed values less than zero or pH values greater than 12. Erroneous data entered as -99 are also removed. The function returns the original data with the QAQC columns removed and \code{NA} (not available) values for observations that do not meet the criteria specified in the function call.

% table for organize functions
%latex.default(to_tab[, "Description", drop = F], file = "", caption = "Organizing functions available from the \\pkg{SWMPr} package. Full documentation for each function is in the help file (e.g., execute \\code{?comb} for individual functions or \\code{help.search(`organize', package = `SWMPr')} for all).",     rowlabel = "Function", colheads = "Description", rowname = to_tab$Functions,     caption.loc = "top", col.just = c("p{3.5in}"), label = "tab:organize",     table.env = FALSE, where = "!tbp")%
\begin{table}[!tbp]
\caption{Organizing functions available from the \pkg{SWMPr} package. Full documentation for each function is in the help file (e.g., execute \code{?comb} for individual functions or \code{help.search(`organize', package = `SWMPr')} for all).\label{tab:organize}} 
\begin{center}
\begin{tabular}{lp{3.5in}}
\hline\hline
\multicolumn{1}{l}{Function}&\multicolumn{1}{c}{Description}\tabularnewline
\hline
\code{comb}&Combines \code{"swmpr"} objects to a common time series using setstep, such as combining the weather, nutrients, and water quality data for a single station.\tabularnewline
\code{qaqc}&Remove QAQC columns and remove data based on QAQC flag values for a \code{"swmpr"} object.\tabularnewline
\code{qaqcchk}&View a summary of the number of observations in a \code{"swmpr"} object that are assigned to each QAQC flag used by CDMO.\tabularnewline
\code{rem\_reps}&Remove replicate nutrient data that occur on the same day.  The default is to average replicates.\tabularnewline
\code{setstep}&Format data from a \code{"swmpr"} object to a continuous time series at a given timestep.\tabularnewline
\code{subset}&Subset by dates and/or columns for a \code{"swmpr"} object.  This is a method passed to the generic \code{subset} function in the base installation.\tabularnewline
\hline
\end{tabular}\end{center}

\end{table}


\begin{example}
# qaqc screen for a swmpr object, retain only '0'
qaqc(dat)

# retain all data regardless of flag
qaqc(dat, qaqc_keep = NULL)

# retain only '0' and '-1' flags
qaqc(dat, qaqc_keep = c(0, -1))
\end{example}

SWMP data often contain observations above or below the detection limit for the sensor or laboratory method used to quantify the parameters.  For example, nutrient data exceeding the high sensor range are assigned a QAQC flag of -5, whereas data below the low sensor range are assigned a QAQC flag of -4.  The presence of censored data is non-trivial and can influence the types of analyses that are appropriate for a time series \citep{Helsel12}.  A detailed discussion of methods for evaluating censored data is beyond the scope of the manuscript and existing methods for R are provided by other packages \citep[e.g., \CRANpkg{cents},][]{McLeod14}.  However, the functions in \pkg{SWMPr} can be used to identify censored data based on the appropriate QAQC flag for a parameter.  Viewing this information can be helpful for determining how to further process the data with the \code{qaqc} function or alternative methods outside of \pkg{SWMPr}.  The \code{qaqcchk} function returns a \code{data.frame} of the number of observations for a parameter that are assigned to all QAQC flags, including those for censored data.  SWMP data should not be analyzed without viewing this information to determine an appropriate method to address data with questionable QAQC flags.    

\begin{example}
# view the number of observations in each QAQC flag
qaqcchk(dat)
\end{example}

A subset method added to the existing generic \code{subset} function in R is available for \code{"swmpr"} objects.  This function is used to subset the data by date and/or a selected parameter.  The date can be a single value or as two dates to select records within the range. The former case requires a binary operator as a character string passed to the \code{operator} argument, such as \code{'>'} or \code{'<='}.  The subset argument for the date(s) must also be a character string of the format YYYY-mm-dd HH:MM for each element (e.g., \code{'2007-01-01 06:30'}). 

\begin{example}
# import data
data(apaebmet)
dat <- apaebmet

# select two parameters from dat
subset(dat, select = c('rh', 'bp'))

# subset records greater than or equal to a date
subset(dat, subset = '2013-01-01 0:00', operator = '>=')

# subset records within a date range, select two parameters
subset(dat, subset = c('2012-07-01 6:00', '2012-08-01 18:15'),
  select = c('atemp', 'totsorad'))
\end{example}

The \code{setstep} function formats a \code{"swmpr"} object to a continuous time series at a given time step.  The function also has a default method making it useful for standardizing arbitrary time series to a given interval.  The first argument of the function, \code{timestep}, specifies the desired time step in minutes starting from the nearest hour of the first observation.  The second argument, \code{differ}, specifies the allowable tolerance in minutes for matching existing observations to the defined time steps in cases where the two are dissimilar.  Values for \code{differ} that are greater than one half the value of \code{timestep} are not allowed to prevent duplication of existing data.  Likewise, the default value for \code{differ} is one half the time step.

\begin{example}
# import, qaqc removal
data(apadbwq)
dat <- qaqc(apadbwq)

# convert time series to two hour invervals
# tolerance of +/- 30 minutes for matching existing data
setstep(dat, timestep = 120, differ = 30)
\end{example}

The \code{comb} function is used to combine multiple \code{"swmpr"} objects into a single object with a continuous time series at a given step.  The \code{setstep} function is used internally such that \code{timestep} and \code{differ} are accepted arguments for \code{comb}.  Data are combined by creating a master time series that is used to iteratively merge all \code{"swmpr"} objects.  The time series for merging depends on the value passed to the \code{method} argument.  Passing \code{'union'} to \code{method} will create a time series that is continuous from the earliest and latest dates for all input objects, whereas \code{'intersect'} will create a continuous time series from the set of dates that are shared between input objects.  A character string or numeric vector can also be used to specify which of the input objects to use as the master time series for combining.  As with \code{setstep}, a default method for \code{comb} is provided to allow use with arbitrary data structures.  Both functions treat missing data as \code{NA} values, either for observations that exceed the allowable tolerance for the \code{differ} argument of \code{setstep} or for portions of time series that do not overlap given the \code{method} argument passed to \code{comb}.   

\begin{example}
# get nut, wq, and met data as separate objects
data(apacpnut)
data(apacpwq)
data(apaebmet)
swmp1 <- apacpnut
swmp2 <- apacpwq
swmp3 <- apaebmet

# combine nut and wq data by union
comb(swmp1, swmp2, method = 'union')

# combine nut and met data by intersect
comb(swmp1, swmp3, method = 'intersect')

# combine nut, wq, and met data by nut time series, two hour time step
comb(swmp1, swmp2, swmp3, timestep = 120, method = 'apacpnut')
\end{example}

\subsection{Data analysis}

The analysis functions range from general purpose tools for time series analysis to more specific functions for working with continuous monitoring data in estuaries (Table~\ref{tab:analyze}).  The general purpose tools are \code{"swmpr"} methods for existing S3 generics or are slight modifications to existing functions. These include \code{aggreswmp} to combine observations by set periods of time (e.g., weeks, months), \code{smoother} to average time series with a moving window, and \code{approx} to substitute missing data with interpolated values.  For brevity, the general functions are not discussed.  More specific functions for environmental time series include decomposition functions, \code{decomp} and \code{decomp\_cj}, and functions to estimate and plot ecosystem metabolism from combined water quality and weather data.  Several plotting methods to facilitate analysis are also descibed below.  

% table for analysis functions
%latex.default(to_tab[, "Description", drop = F], file = "", caption = "Analysis functions available from the \\pkg{SWMPr} package.  Full documentation for each function is in the help file (e.g., execute \\code{?aggreswmp} for individual functions or \\code{help.search(`analyze', package = `SWMPr')} for all).",     rowlabel = "Function", colheads = "Description", rowname = to_tab$Functions,     caption.loc = "top", col.just = c("p{3.5in}"), label = "tab:analyze",     table.env = FALSE, where = "!tbp")%
\begin{table}[!tbp]
\caption{Analysis functions available from the \pkg{SWMPr} package.  Full documentation for each function is in the help file (e.g., execute \code{?aggreswmp} for individual functions or \code{help.search(`analyze', package = `SWMPr')} for all).\label{tab:analyze}} 
\begin{center}
\begin{tabular}{lp{3.5in}}
\hline\hline
\multicolumn{1}{l}{Function}&\multicolumn{1}{c}{Description}\tabularnewline
\hline
\code{aggreswmp}&Aggregate \code{"swmpr"} objects for different time periods - years, quarters, months,  weeks, days, or hours.  The aggregation function defaults to the mean.\tabularnewline
\code{aggremetab}&Aggregate metabolism data from a \code{"swmpr"} object.  This is primarly used within \code{plot\_metab} but may be useful for simple summaries of daily metabolism data.\tabularnewline
\code{ecometab}&Estimate ecosystem metabolism for a combined water quality and weather dataset using the open-water method \citep{Odum56}.\tabularnewline
\code{decomp}&Decompose a \code{"swmpr"} time series into trend, seasonal, and residual components.  This is a simple wrapper to \code{decompose} \citep{Kendall83}.  Decomposition of monthly or daily trends is possible.\tabularnewline
\code{decomp\_cj}&Decompose a \code{"swmpr"} time series into grandmean, annual, seasonal, and events components.  This is a simple wrapper to \code{decompTs} in the \CRANpkg{wq} package \citep{Jassby14}.  Only monthly decomposition is possible.\tabularnewline
\code{hist}&Plot a histogram for a single variable.\tabularnewline
\code{lines}&Add lines to an existing plot created with \code{plot}.\tabularnewline
\code{map\_reserve}&Create a map of all stations in a reserve using the \CRANpkg{ggmap} package \citep{Kahle13}.\tabularnewline
\code{na.approx}&Linearly interpolate missing data (\code{NA} values) in a \code{"swmpr"} object.\tabularnewline
\code{overplot}&Plot multiple time series in a \code{"swmpr"} object on the same y-axis.\tabularnewline
\code{plot}&Plot a univariate  time series for a \code{"swmpr"} object.\tabularnewline
\code{plot\_metab}&Plot ecosystem metabolism estimates after running \code{ecometab} on a combined \code{"swmpr"} object.\tabularnewline
\code{plot\_summary}&Create summary plots of seasonal/annual trends and anomalies for a single parameter.\tabularnewline
\code{smoother}&Smooth \code{"swmpr"} objects with a moving window average, passed to \code{filter}.\tabularnewline
\hline
\end{tabular}\end{center}

\end{table}


The disaggregation of time series into additive or multiplicative components is a common application for trend analysis.  The \code{decomp} function is a simple wrapper to \code{decompose} \citep{Kendall83} that separates a time series into a trend, cyclical variation (e.g., daily or annual), and the remainder  (Figure~\ref{fig:decomp_ex1}).  An additive decomposition assumes that the cyclical component of the time series is stationary (i.e., the variance is constant), otherwise a multiplicative decomposition can be used.  The \code{frequency} argument describes the periodicity of the cyclical parameter in units of the native time step.  For example, the \code{frequency} for a parameter with daily periodicity would be 96 if the time step is 15 minutes (24 hours * 60 minutes / 15 minutes).  For simplicity, character strings of \code{'daily'} or \code{'annual'} can be supplied in place of numeric values, although any number can be used to identify an arbitrary cyclical component.  A starting value of the time series must be supplied in the latter case that indicates the sequence in the cycle for the first observation (see \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ts.html}{\code{ts}} for details).

\begin{example}
# get data
data(apadbwq)
dat <- apadbwq

# subset for daily decomposition
dat <- subset(dat, subset = c('2013-07-01 00:00', '2013-07-31 00:00'))

# daily decomposition of DO and plot
dc_dat <- decomp(dat, param = 'do_mgl', frequency = 'daily')
plot(dc_dat)
\end{example}
\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{decomp_ex1-1} 

}

\caption[An additive decomposition of dissolved oxygen into a trend, seasonal (daily), and random component using the \code{decomp} function]{An additive decomposition of dissolved oxygen into a trend, seasonal (daily), and random component using the \code{decomp} function.}\label{fig:decomp_ex1}
\end{figure}

An alternative approach for decomposition is provided by the \code{decomp\_cj} function, which is a simple wrapper to the \code{decompTs} function in the \CRANpkg{wq} package \citep{Cloern10,Jassby14}.  The \code{decomp\_cj} function is a monthly decomposition for characterizing relatively long-term trends.  This approach works best for nutrient data that are typically obtained on a monthly cycle.  The time series is decomposed into the grandmean, annual, seasonal, and events components (Figure~\ref{fig:decomp_ex2}), as compared to trend, seasonal, and random components for the \code{decomp} function above.  For both functions, the random or events components can be considered anomalies that do not follow the trends in the remaining categories.  Additional arguments passed to \code{decompTs} can be used with \code{decomp\_cj}, such as \code{startyr}, \code{endyr}, and \code{type}.  Values passed to \code{type} are \code{mult} (default) or \code{add}, referring to multiplicative or additive decomposition.

\begin{example}
# get data
data(apacpnut)
dat <- apacpnut
dat <- qaqc(dat, qaqc_keep = NULL)

# decomposition of chl
decomp_cj(dat, param = 'chla_n')
\end{example}

\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{decomp_ex2-1} 

}

\caption[Additive decomposition of a multi-year chlorophyll time series into the grandmean, annual, seasonal, and events components using the \code{decomp\_cj} function]{Additive decomposition of a multi-year chlorophyll time series into the grandmean, annual, seasonal, and events components using the \code{decomp\_cj} function.}\label{fig:decomp_ex2}
\end{figure}

Estimates of ecosystem metabolism provide a measure of system productivity to evaluate whether an ecosystem is a net source or sink of organic material.  The open-water method \citep{Odum56} is a common approach to quantify metabolism using a mass balance equation that describes the change in dissolved oxygen over time from the balance between photosynthetic and respiration processes, corrected using an empirically constrained air-sea gas diffusion model \citep{Ro06,Thebault08}. A detailed discussion of the method is beyond the scope of this article, although users are encouraged to consult references herein for additional information (see \citet{Kemp12,Needoba12,Caffrey14}, also the package help files).  Methods for estuaries have not previously been available in R, although the \CRANpkg{StreamMetabolism} package provides an approach for freshwater systems.  The following is an example that shows use of \code{ecometab} with a combined water quality and weather data set.  Monthly aggregations of the raw, daily estimates are plotted using \code{plot\_metab} (Figure~\ref{fig:metab_ex}).

\begin{example}
## import water quality and weather data
data(apadbwq)
data(apaebmet)

## qaqc, combine
wq <- qaqc(apadbwq)
met <- qaqc(apaebmet)
dat <- comb(wq, met)

## estimate metabolism
res <- ecometab(dat, trace = FALSE)
plot_metab(res)
\end{example}
\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{metab_ex-1} 

}

\caption[Monthly means (95\% confidence) of ecosystem metabolism estimates (net ecosystem metabolism, gross production, and total respiration) for combined water quality and weather data for two years at Apalachicola Bay, Florida]{Monthly means (95\% confidence) of ecosystem metabolism estimates (net ecosystem metabolism, gross production, and total respiration) for combined water quality and weather data for two years at Apalachicola Bay, Florida.}\label{fig:metab_ex}
\end{figure}

Exploratory graphics are also useful for evaluating general trends in observed data.  Several graphics showing seasonal and annual trends for a single SWMP parameter can be obtained using the \code{plot\_summary} function (Figure~\ref{fig:summary_ex}).  The plots include monthly distributions, monthly anomalies, and annual anomalies in multiple formats.  An interactive \CRANpkg{shiny} web application \citep{Chang15} that uses this function is available for viewing results for all SWMP sites (see the \nameref{swmp_apps} section).

\begin{example}
## import data
data(apacpnut)
dat <- qaqc(apacpnut)

## plot
plot_summary(dat, param = 'chla_n', years = c(2007, 2013))
\end{example}

\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{summary_ex-1} 

}

\caption[Summaries of a multi-year chlorophyll time series using the \code{plot\_summary} function]{Summaries of a multi-year chlorophyll time series using the \code{plot\_summary} function.  Summaries include monthly distributions (means on top left, quantiles on bottom left), monthly histograms (center), monthly means by year (top right), deviation from monthly means (middle right), and annual trends as deviations from the grand mean (bottom right)}\label{fig:summary_ex}
\end{figure}

Similarly, the \code{overplot} function provides an alternative approach to viewing observed data from the same station.  This function uses the base \pkg{graphics} package to plot multiple time series on the same y-axis (Figure~\ref{fig:overplot}).

\begin{example}
## import data
data(apacpwq)
dat <- qaqc(apacpwq)

## plot
overplot(dat, select = c('depth', 'do_mgl', 'ph', 'turb'),
  subset = c('2013-01-01 0:0', '2013-02-01 0:0'), lwd = 2)
\end{example}

\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{overplot-1} 

}

\caption[The \code{overplot} function plots multiple variables on the same y-axis]{The \code{overplot} function plots multiple variables on the same y-axis.}\label{fig:overplot}
\end{figure}

Finally, the \code{map\_reserve} function can be used to create a map of stations at a reserve using the \CRANpkg{ggmap} package (Figure~\ref{fig:map_ex}, \citet{Kahle13}). The function uses Google maps of four types that can be set with the \code{map\_type} argument: terrain (default), satellite, roadmap, or hybrid.  The \code{zoom} argument can be chosen through trial and error depending on the spatial extent of the reserve.

\begin{example}
# plot the stations at Jacques Cousteau reserve
map_reserve('jac')
\end{example}

\begin{figure}[!h]

{\centering \includegraphics[width=\textwidth]{map_ex-1} 

}

\caption[Locations of all sites at the Jacques Cousteau reserve using the \code{map\_reserve} function]{Locations of all sites at the Jacques Cousteau reserve using the \code{map\_reserve} function.}\label{fig:map_ex}
\end{figure}

\section{Applications using the \pkg{SWMPr} package}
\label{swmp_apps}

Two \CRANpkg{shiny} web applications illustrate the improved ability to synthesize and evaluate multi-year time series using \pkg{SWMPr}.  The first application evaluates trends in SWMP data within and between sites using an interactive \pkg{leaflet} map (\citet{Cheng15}, Figure~\ref{fig:swmp_comp}): \href{https://beckmw.shinyapps.io/swmp_comp}{https://beckmw.shinyapps.io/swmp\_comp}.  Trends between reserves can be viewed using the map, whereas trends at individual sites can be viewed by clicking on a map location.  Site-level trends are shown below the map with a simple linear regression to show an increase or decrease in values over time, whereas trends between sites are shown on the map for each station as circles that identify the direction and significance of the trend.  More robust methods for evaluating trends are currently not provided by the application and the use of simple linear regression is meant for initial exploratory analysis.  The second application provides graphical summaries of water quality, weather, or nutrient station data at individual stations using the \code{plot\_summary} function: \href{https://beckmw.shinyapps.io/swmp_summary/}{https://beckmw.shinyapps.io/swmp\_summary}.  The output is identical to Figure~\ref{fig:summary_ex} with the addition of drop down menus to select the station, date range, and parameter for plotting.

\begin{figure}[!h]
\begin{center}
\includegraphics[width = \textwidth]{swmp_comp.pdf}
\caption{Online application for comparing trends in SWMP data parameters using an interactive map.  Link: \href{https://beckmw.shinyapps.io/swmp_comp}{https://beckmw.shinyapps.io/swmp\_comp}}
\label{fig:swmp_comp}
\end{center}
\end{figure}

\section{Conclusions}

\pkg{SWMPr} was developed to augment existing data management programs (i.e., CDMO) by providing a bridge betwen the raw data and the analysis software through its numerous data retrieval functions (Table~\ref{tab:retrieve}).  Established QAQC methods and data processing techniques are also enhanced with \pkg{SWMPr} by functions that filter observations for different QAQC flags (\code{qaqc}) and subset by selected dates or variables (\code{subset}).  Additionally, challenges comparing differents datasets are addressed by the \code{setstep} and \code{comb} functions that standardize and combine time series.  Finally, the analysis functions provide numerous tools to implement common analyses for time series and more specific methods for water quality data.  Further development of the package will include modifications and additional functions to better integrate data analysis with the quality of information provided by SWMP.  Several functions include default methods to extend use beyond the \code{"swmpr"} object and additional development will continue to focus on modifying the package to handle arbitrary data structures.  These challenges are not unique to the SWMP database such that many of the functions will facilitate evaluations of more generic time series datasets.  

\section{Acknowledgments}

I acknowledge the significant work of NERRS researchers and staff that has allowed access to high-quality monitoring data.  Thanks to Todd O'Brien for the inspiration for the online widgets. Thanks to Mike Murrell and Jim Hagy III for assistance with the ecosystem metabolism functions. Thanks to Jeff Hollister for providing useful comments on an earlier draft.

\bibliography{beck}

\address{Marcus W Beck\\
  ORISE Research Participation Program\\
  USEPA National Health and Environmental Effects Research Laboratory, Gulf Ecology Division\\
  1 Sabine Island Drive, Gulf Breeze, FL 32651\\
  USA\\}
\email{beck.marcus@epa.gov}
